{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Training (fine-tuning) SloBERTa Transformer model on SLED smalltrain"]},{"cell_type":"markdown","metadata":{"id":"Bf0Oql_1HOtk"},"source":["This notebook is prepared to be viewed on Google Colab. However, I performed most of the experiment on Kaggle (by importing the same notebook and data) instead of Google Colab, because while Kaggle gives you 35-40 hours of GPU per week, Google Colab does not state how much working on GPU it allows, and after I spent one day doing hyperparameter search, I got a message that I spent it all without stating when I'll be able to use it again. Therefore, I recommend using Kaggle for lengthy experiments on GPU."]},{"cell_type":"markdown","metadata":{},"source":["Before starting, click on the \"RAM\" and \"Disk\" information on the top right part of the page and click \"Change runtime type\" > Choose \"GPU\" as \"Hardware accelerator\"."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:04:09.436216Z","iopub.status.busy":"2022-09-05T06:04:09.435827Z","iopub.status.idle":"2022-09-05T06:04:09.967336Z","shell.execute_reply":"2022-09-05T06:04:09.966372Z","shell.execute_reply.started":"2022-09-05T06:04:09.436182Z"},"id":"lTXoWplYG48h","trusted":true},"outputs":[],"source":["# install the libraries necessary for data wrangling, prediction and result analysis\n","import json\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score, recall_score\n","import torch\n","from numba import cuda\n","import time\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:02:51.479216Z","iopub.status.busy":"2022-09-05T06:02:51.478415Z","iopub.status.idle":"2022-09-05T06:03:33.067084Z","shell.execute_reply":"2022-09-05T06:03:33.066071Z","shell.execute_reply.started":"2022-09-05T06:02:51.479100Z"},"id":"zZqgErWfG48i","outputId":"f4e7f537-103e-4f41-b0ef-affddddd7149","trusted":true},"outputs":[],"source":["# Install transformers\n","# (this needs to be done on Colab each time you start the session)\n","!pip install -q transformers\n","\n","# Install the simpletransformers\n","!pip install -q simpletransformers\n","from simpletransformers.classification import ClassificationModel"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:03:33.070137Z","iopub.status.busy":"2022-09-05T06:03:33.069286Z","iopub.status.idle":"2022-09-05T06:03:58.743518Z","shell.execute_reply":"2022-09-05T06:03:58.742411Z","shell.execute_reply.started":"2022-09-05T06:03:33.070081Z"},"id":"FvvJgvBKG48i","outputId":"a16a7c0a-02e1-454c-eb0d-d650607aba70","trusted":true},"outputs":[],"source":["# Install wandb - this will be useful for inspecting the results of a hyperparameter search. You need to create an account on Wandb: https://wandb.ai/\n","!pip install -q wandb\n","\n","import wandb\n","\n","# Login to wandb\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"2WjS5ZNZG48k"},"source":["### Import the data"]},{"cell_type":"markdown","metadata":{},"source":["You need to prepare the data into a format that is accepted by Transformers (dataframe with the first column \"text\" and the second column \"labels\"). The data was prepared according to the code here: https://github.com/TajaKuzman/FastText-Classification-SLED/blob/main/0-analyse-data-prepare-for-transformers.ipynb"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:04:15.193978Z","iopub.status.busy":"2022-09-05T06:04:15.193038Z","iopub.status.idle":"2022-09-05T06:04:15.693308Z","shell.execute_reply":"2022-09-05T06:04:15.692290Z","shell.execute_reply.started":"2022-09-05T06:04:15.193942Z"},"id":"bnkXFivrG48k","outputId":"1a889630-04f7-4574-e7b4-7accfa0a4206","trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"/kaggle/input/sledcategorizationdataset/SLED-for-Transformers-train.csv\", sep=\"\\t\", index_col=0)\n","dev_df = pd.read_csv(\"/kaggle/input/sledcategorizationdataset/SLED-for-Transformers-dev.csv\", sep=\"\\t\", index_col = 0)\n","test_df = pd.read_csv(\"/kaggle/input/sledcategorizationdataset/SLED-for-Transformers-test.csv\", sep=\"\\t\", index_col = 0)\n","\n","# See the sizes of splits.\n","# I noticed that when I ran this code on Google Colab, it did not import the entire train split every time (sometimes the size was a couple instances smaller than it should be) - if this happens, just run this cell again, until the size is fine (it should be 9990). I did not have this problem on Kaggle.\n","print(\"Train shape: {}, Dev shape: {}, Test shape: {}.\".format(train_df.shape, dev_df.shape, test_df.shape))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:04:21.627961Z","iopub.status.busy":"2022-09-05T06:04:21.627371Z","iopub.status.idle":"2022-09-05T06:04:21.642537Z","shell.execute_reply":"2022-09-05T06:04:21.641544Z","shell.execute_reply.started":"2022-09-05T06:04:21.627929Z"},"id":"vmt2VPzoG48k","outputId":"7558491b-eb4c-48a3-910e-906bccb1d21a","trusted":true},"outputs":[],"source":["# Inspect the beginning of the train split.\n","train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"HJzQ5uQcG48k"},"source":["## Training and saving"]},{"cell_type":"markdown","metadata":{"id":"oh9j3bUIG48l"},"source":["We will use the monolingual SloBERTa model\n","https://huggingface.co/EMBEDDIA/sloberta"]},{"cell_type":"markdown","metadata":{},"source":["For training, I'll use the simple transformer library which is much more user-friendly than the hugging face library. They also have very nice instructions on everything: https://simpletransformers.ai/docs/installation/, including tutorials, I recommend reading it."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:04:25.185697Z","iopub.status.busy":"2022-09-05T06:04:25.185232Z","iopub.status.idle":"2022-09-05T06:04:25.194299Z","shell.execute_reply":"2022-09-05T06:04:25.193386Z","shell.execute_reply.started":"2022-09-05T06:04:25.185662Z"},"id":"IpPQuSt4G48l","trusted":true},"outputs":[],"source":["# Set the \"TOKENIZERS_PARALLELISM\" to false to avoid getting an error when training the model.\n","import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:04:27.123887Z","iopub.status.busy":"2022-09-05T06:04:27.123526Z","iopub.status.idle":"2022-09-05T06:04:27.136553Z","shell.execute_reply":"2022-09-05T06:04:27.135203Z","shell.execute_reply.started":"2022-09-05T06:04:27.123859Z"},"id":"CsA2-xYyG48l","outputId":"9c24b856-a6b4-4aaf-eba0-faa3c62887bd","trusted":true},"outputs":[],"source":["# Create a list of labels\n","LABELS = train_df.labels.unique().tolist()\n","LABELS"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:04:30.917914Z","iopub.status.busy":"2022-09-05T06:04:30.917115Z","iopub.status.idle":"2022-09-05T06:04:37.446097Z","shell.execute_reply":"2022-09-05T06:04:37.445187Z","shell.execute_reply.started":"2022-09-05T06:04:30.917881Z"},"id":"2Uk3QBetG48l","outputId":"95c04bd3-2262-4d90-a973-dd7f14d773de","trusted":true},"outputs":[],"source":["# Initialize Wandb (change the names of project, entity and \"name\" according to your project in Wandb)\n","wandb.init(project=\"SLED-categorization\", entity=\"tajak\", name=\"SloBERTa-hyperparameter-search\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:04:40.897312Z","iopub.status.busy":"2022-09-05T06:04:40.896771Z","iopub.status.idle":"2022-09-05T06:04:40.910083Z","shell.execute_reply":"2022-09-05T06:04:40.909004Z","shell.execute_reply.started":"2022-09-05T06:04:40.897264Z"},"id":"w5dNhA4hG48m","outputId":"0081e07e-fe88-4aa0-abcf-7f5743cb478d","trusted":true},"outputs":[],"source":["# Calculate how many steps will each epoch have\n","# Num steps in epoch = training samples / batch size\n","steps_per_epoch = int(9990/8)\n","steps_per_epoch"]},{"cell_type":"markdown","metadata":{"id":"D2gsrgCQIImz"},"source":["### Hyperparameter search"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-07-29T06:59:27.044920Z","iopub.status.busy":"2022-07-29T06:59:27.044530Z","iopub.status.idle":"2022-07-29T06:59:27.051272Z","shell.execute_reply":"2022-07-29T06:59:27.050401Z","shell.execute_reply.started":"2022-07-29T06:59:27.044871Z"},"id":"oBUMVyTBG48m","trusted":true},"source":["I evaluated the model per every 10th epoch - per 12480 steps. I first trained the model while evaluating it to find the optimal number of epochs. Based on the information on changes in training and evaluation loss which I observed on Wandb, I found out which epochs are the most optimal (epochs before which the evaluation loss starts rising again). Then I trained the model and tested it on dev for each of possible optimal epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-23T11:14:46.044012Z","iopub.status.busy":"2022-08-23T11:14:46.043127Z","iopub.status.idle":"2022-08-23T11:15:42.456646Z","shell.execute_reply":"2022-08-23T11:15:42.455651Z","shell.execute_reply.started":"2022-08-23T11:14:46.043973Z"},"id":"bCz4gGWzG48m","outputId":"72db1891-b6f6-4219-9c6b-363a05f3843d","trusted":true},"outputs":[],"source":["# Create a TransformerModel\n","sloberta_model = ClassificationModel(\n","    # For each model, you need to specify its model type and its name. You can find this information on the hugging face page of the model (https://huggingface.co/EMBEDDIA/sloberta): you'll find the model type in files > config.json; and the name if you click on the button \"Use in Transformers\"\n","        \"camembert\", \"EMBEDDIA/sloberta\",\n","        num_labels=len(LABELS),\n","        use_cuda=True,\n","        # Define the hyperparameters (I'll only experiment with epochs, for others, I just use the values that worked nicely in past experiments)\n","        args= {\n","            \"num_train_epochs\": 30,\n","            \"train_batch_size\":8,\n","            \"learning_rate\": 1e-5,\n","            \"labels_list\": LABELS,\n","            \"max_seq_length\": 512,\n","            # Here, write in the name of your Wandb project\n","            \"wandb_project\": 'SLED-categorization',\n","            \"silent\": True,                        \n","            # Use these parameters if you want to evaluate during training\n","            \"evaluate_during_training\": True,\n","            \"evaluate_during_training_steps\": steps_per_epoch*10,\n","            \"evaluate_during_training_verbose\": True,\n","            \"use_cached_eval_features\": True,\n","            'reprocess_input_data': True,\n","            # I use the hyperparameters bellow to prevent filling up the memory. Disable no_save: True and no_cache: True if you want to save the model\n","            \"overwrite_output_dir\": True,\n","            \"no_cache\": True,\n","            \"no_save\": True,\n","            \"save_steps\": -1,\n","            \"save_model_every_epoch\":False\n","            }\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-23T11:16:20.475361Z","iopub.status.busy":"2022-08-23T11:16:20.474372Z","iopub.status.idle":"2022-08-23T11:35:47.348058Z","shell.execute_reply":"2022-08-23T11:35:47.346990Z","shell.execute_reply.started":"2022-08-23T11:16:20.475323Z"},"id":"isOQFWADG48m","outputId":"83631a22-54e9-42e3-cfd1-356ea437e892","trusted":true},"outputs":[],"source":["# Train the model\n","\n","# Log time to see how long it takes\n","training_start_time = time.time()\n","\n","# Train the model and evaluate it - you need to specify the evaluation file as well\n","sloberta_model.train_model(train_df, eval_df = dev_df)\n","\n","print(f\"Training and evaluation took {round((time.time() - training_start_time)/60,2)} minutes.\")"]},{"cell_type":"markdown","metadata":{"id":"XApAjnsUG48m"},"source":["Based on evaluation during training, analysed on Wandb, the optimum epoch is between 2 and 8 epochs (see graph on GitHub: https://github.com/TajaKuzman/FastText-Classification-SLED#hyperparameter-search)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:07:33.838298Z","iopub.status.busy":"2022-09-05T06:07:33.837912Z","iopub.status.idle":"2022-09-05T06:07:33.844953Z","shell.execute_reply":"2022-09-05T06:07:33.843829Z","shell.execute_reply.started":"2022-09-05T06:07:33.838264Z"},"id":"753cKK1REqw3","trusted":true},"outputs":[],"source":["previous_results = []"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T08:21:09.613260Z","iopub.status.busy":"2022-09-05T08:21:09.612883Z","iopub.status.idle":"2022-09-05T08:21:09.626990Z","shell.execute_reply":"2022-09-05T08:21:09.625801Z","shell.execute_reply.started":"2022-09-05T08:21:09.613229Z"},"id":"wu3i2hUYG48m","trusted":true},"outputs":[],"source":["# Create a function that you'll use for testing the model\n","\n","def testing(test_df, test_name, epoch):\n","    \"\"\"\n","    This function takes the test dataset and applies the trained model on it to infer predictions.\n","    It also prints and saves a confusion matrix, calculates the F1 scores and saves the results in a list of results.\n","\n","    Args:\n","    - test_df (pandas DataFrame)\n","    - test_name\n","    - epoch: num_train_epochs\n","    \"\"\"\n","    # Get the true labels\n","    y_true = test_df.labels\n","\n","    # Define the model\n","    model = sloberta_model\n","    \n","    # Calculate the model's predictions on test\n","    def make_prediction(input_string):\n","        return model.predict([input_string])[0][0]\n","\n","    # Use the model to predict the labels\n","    y_pred = test_df.text.apply(make_prediction)\n","\n","    # Calculate the scores\n","    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n","    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n","    print(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}\")\n","\n","    # Plot the confusion matrix:\n","    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n","    plt.figure(figsize=(9, 9))\n","    plt.imshow(cm, cmap=\"Oranges\")\n","    for (i, j), z in np.ndenumerate(cm):\n","        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n","    classNames = LABELS\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    tick_marks = np.arange(len(classNames))\n","    plt.xticks(tick_marks, classNames, rotation=90)\n","    plt.yticks(tick_marks, classNames)\n","    plt.title(f\"{test_name}\")\n","\n","    plt.tight_layout()\n","    fig1 = plt.gcf()\n","    plt.show()\n","    plt.draw()\n","    # Save the confusion matrix\n","    fig1.savefig(f\"Confusion-matrix-{test_name}.png\",dpi=100)\n","\n","    # Add classification report\n","    print(classification_report(y_true, y_pred, labels = LABELS))\n","\n","    # Save the results:\n","    rezdict = {\n","        \"experiment\": test_name,\n","        \"num_train_epochs\": epoch,\n","        \"train_batch_size\":8,\n","        \"learning_rate\": 1e-5,\n","        \"microF1\": micro,\n","        \"macroF1\": macro,\n","        \"y_true\": y_true.to_dict(),\n","        \"y_pred\": y_pred.to_dict(),\n","        }\n","    previous_results.append(rezdict)\n","\n","    #Save intermediate results (just in case)\n","    backup = []\n","    backup.append(rezdict)\n","    with open(f\"backup-results-{test_name}.json\", \"w\") as backup_file:\n","        json.dump(backup,backup_file, indent= \"\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-02T09:52:33.924310Z","iopub.status.busy":"2022-09-02T09:52:33.923585Z","iopub.status.idle":"2022-09-02T13:04:42.035418Z","shell.execute_reply":"2022-09-02T13:04:42.034227Z","shell.execute_reply.started":"2022-09-02T09:52:33.924270Z"},"id":"Xqhyr3fRG48n","outputId":"bf9b8878-cb63-4785-ab7a-26c0bfd4ea77","trusted":true},"outputs":[],"source":["# Train the model for various epochs to find the optimum number of epochs\n","#epochs = [2, 4, 6, 8]\n","epochs = [8, 10]\n","\n","for epoch in epochs:\n","    sloberta_model = ClassificationModel(\n","                \"camembert\", \"EMBEDDIA/sloberta\",\n","                num_labels=len(LABELS),\n","                use_cuda=True,\n","                args= {\n","                    \"overwrite_output_dir\": True,\n","                    \"num_train_epochs\": epoch,\n","                    \"train_batch_size\":8,\n","                    \"learning_rate\": 1e-5,\n","                    \"labels_list\": LABELS,\n","                    # The following parameters (no_cache, no_save) are commented out if I want to save the model\n","                    \"no_cache\": True,\n","                    \"no_save\": True,\n","                    \"max_seq_length\": 512,\n","                    \"save_steps\": -1,\n","                    # Only the trained model will be saved - to prevent filling all of the space\n","                    \"save_model_every_epoch\":False,\n","                    \"wandb_project\": 'SLED-categorization',\n","                    \"silent\": True,\n","                    }\n","                )\n","\n","    # Train the model\n","    sloberta_model.train_model(train_df)\n","    \n","    # Test the model on dev_df\n","    testing(dev_df, f\"SLED-trainsmall-SLOBERTA-dev-epoch-search:{epoch}\", epoch)"]},{"cell_type":"markdown","metadata":{"id":"igKmu89GG48n"},"source":["Optimum number of epochs is 8."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-09-02T13:26:56.341204Z","iopub.status.busy":"2022-09-02T13:26:56.340563Z","iopub.status.idle":"2022-09-02T13:26:56.387409Z","shell.execute_reply":"2022-09-02T13:26:56.386422Z","shell.execute_reply.started":"2022-09-02T13:26:56.341151Z"},"id":"W4eE9BU1G48n","trusted":true},"outputs":[],"source":["# Compare the results by creating a dataframe from the previous_results dictionary:\n","results_df = pd.DataFrame(previous_results)\n","\n","results_df"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-09-02T13:27:27.025246Z","iopub.status.busy":"2022-09-02T13:27:27.024878Z","iopub.status.idle":"2022-09-02T13:27:27.047994Z","shell.execute_reply":"2022-09-02T13:27:27.047122Z","shell.execute_reply.started":"2022-09-02T13:27:27.025214Z"},"id":"RrGQ_xkcG48n","trusted":true},"outputs":[],"source":["# Save the file with updated results.\n","with open(\"SLED-SloBERTa-trainsmall-hyperparameter-search-results.json\", \"w\") as results_file:\n","    json.dump(previous_results,results_file, indent= \"\")"]},{"cell_type":"markdown","metadata":{},"source":["Train and save the model, using 8 epochs."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:08:05.401331Z","iopub.status.busy":"2022-09-05T06:08:05.400946Z","iopub.status.idle":"2022-09-05T06:08:41.737044Z","shell.execute_reply":"2022-09-05T06:08:41.736097Z","shell.execute_reply.started":"2022-09-05T06:08:05.401298Z"},"id":"kL5xMuUJG48o","trusted":true},"outputs":[],"source":["# Create a TransformerModel\n","sloberta_model = ClassificationModel(\n","        \"camembert\", \"EMBEDDIA/sloberta\",\n","        num_labels=len(LABELS),\n","        use_cuda=True,\n","        args= {\n","            \"overwrite_output_dir\": True,\n","            \"num_train_epochs\": 8,\n","            \"train_batch_size\":8,\n","            \"learning_rate\": 1e-5,\n","            \"labels_list\": LABELS,\n","            # no_cache and no_save are commented out because I want to save the model\n","            #\"no_cache\": True,\n","            #\"no_save\": True,\n","            \"max_seq_length\": 512,\n","            \"save_steps\": -1,\n","            # Only the trained model will be saved - to prevent filling all of the space\n","            \"save_model_every_epoch\":False,\n","            \"wandb_project\": 'SLED-categorization',\n","            \"silent\": True,\n","            }\n","        )"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T06:08:45.777824Z","iopub.status.busy":"2022-09-05T06:08:45.777470Z","iopub.status.idle":"2022-09-05T07:25:39.092518Z","shell.execute_reply":"2022-09-05T07:25:39.091290Z","shell.execute_reply.started":"2022-09-05T06:08:45.777795Z"},"id":"ct5DPfhZG48o","trusted":true},"outputs":[],"source":["# Train and save the model\n","sloberta_model.train_model(train_df)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T07:57:14.338961Z","iopub.status.busy":"2022-09-05T07:57:14.338289Z","iopub.status.idle":"2022-09-05T07:57:29.603224Z","shell.execute_reply":"2022-09-05T07:57:29.601912Z","shell.execute_reply.started":"2022-09-05T07:57:14.338920Z"},"id":"LGmsh6oFG48o","trusted":true},"outputs":[],"source":["# Save the trained model to Wandb (so you'll be able to access it later - see https://github.com/TajaKuzman/FastText-Classification-SLED/blob/main/Saved_models.md for information on how to use saved models)\n","run = wandb.init(project=\"SLED-categorization\", entity=\"tajak\", name=\"saving-trained-model\")\n","trained_model_artifact = wandb.Artifact(\"SLED-SloBERTa-trainsmall-classifier\", type=\"model\", description=\"a SloBERTa model fine-tuned on the Slovene SLED (trainsmall) dataset, annotated with topic.\")\n","trained_model_artifact.add_dir(\"/kaggle/working/outputs\")\n","run.log_artifact(trained_model_artifact)"]},{"cell_type":"markdown","metadata":{},"source":["## Testing the model"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T08:05:42.746462Z","iopub.status.busy":"2022-09-05T08:05:42.745469Z","iopub.status.idle":"2022-09-05T08:05:42.753656Z","shell.execute_reply":"2022-09-05T08:05:42.752310Z","shell.execute_reply.started":"2022-09-05T08:05:42.746415Z"},"trusted":true},"outputs":[],"source":["# Create a list to save results into\n","previous_results = []"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T08:22:01.725428Z","iopub.status.busy":"2022-09-05T08:22:01.724921Z","iopub.status.idle":"2022-09-05T08:31:18.577805Z","shell.execute_reply":"2022-09-05T08:31:18.576660Z","shell.execute_reply.started":"2022-09-05T08:22:01.725367Z"},"trusted":true},"outputs":[],"source":["# Test the model on the test split\n","testing(test_df, \"SloBERTa-test\", 8)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T08:32:58.213428Z","iopub.status.busy":"2022-09-05T08:32:58.212353Z","iopub.status.idle":"2022-09-05T08:32:58.246688Z","shell.execute_reply":"2022-09-05T08:32:58.245693Z","shell.execute_reply.started":"2022-09-05T08:32:58.213378Z"},"trusted":true},"outputs":[],"source":["# Compare the results by creating a dataframe from the previous_results dictionary:\n","results_df = pd.DataFrame(previous_results)\n","\n","results_df"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-09-05T08:33:07.700289Z","iopub.status.busy":"2022-09-05T08:33:07.699599Z","iopub.status.idle":"2022-09-05T08:33:07.723689Z","shell.execute_reply":"2022-09-05T08:33:07.722655Z","shell.execute_reply.started":"2022-09-05T08:33:07.700255Z"},"trusted":true},"outputs":[],"source":["# Save the results\n","with open(\"SloBERTa-SLED-trainsmall-experiments-Results.json\", \"w\") as results_file:\n","    json.dump(previous_results,results_file, indent= \"\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"vscode":{"interpreter":{"hash":"93d4a695e88da557f0853396ea51c6018a728735920333b5bdbaaf747b0b49f9"}}},"nbformat":4,"nbformat_minor":4}

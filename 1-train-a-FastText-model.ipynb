{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a FastText model on the SLED categorization dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n",
      "WARNING: You are using pip version 21.1.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\tajak\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install FastText\n",
    "%git clone https://github.com/facebookresearch/fastText.git\n",
    "%cd fastText\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'fastText-0.9.2'\n",
      "c:\\Users\\tajak\\Google Drive\\GitHub\\FastText-Classification-on-SLED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "ERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n",
      "WARNING: You are using pip version 21.1.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\tajak\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6344/2739506054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install .'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\n",
    "!unzip v0.9.2.zip\n",
    "\n",
    "%cd fastText-0.9.2\n",
    "\n",
    "!pip install .\n",
    "\n",
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'fastText-0.9.2'\n",
      "c:\\Users\\tajak\\Google Drive\\GitHub\\FastText-Classification-on-SLED\\fastText-0.9.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\tajak\\\\Google Drive\\\\GitHub\\\\FastText-Classification-on-SLED\\\\fastText-0.9.2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd fastText-0.9.2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating python\\fasttext_module\\fasttext.egg-info\n",
      "writing python/fasttext_module\\fasttext.egg-info\\PKG-INFO\n",
      "writing dependency_links to python/fasttext_module\\fasttext.egg-info\\dependency_links.txt\n",
      "writing requirements to python/fasttext_module\\fasttext.egg-info\\requires.txt\n",
      "writing top-level names to python/fasttext_module\\fasttext.egg-info\\top_level.txt\n",
      "writing manifest file 'python/fasttext_module\\fasttext.egg-info\\SOURCES.txt'\n",
      "adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
      "reading manifest file 'python/fasttext_module\\fasttext.egg-info\\SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'python/fasttext_module\\fasttext.egg-info\\SOURCES.txt'\n",
      "installing library code to build\\bdist.win-amd64\\egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build\\lib.win-amd64-3.9\n",
      "creating build\\lib.win-amd64-3.9\\fasttext\n",
      "copying python\\fasttext_module\\fasttext\\FastText.py -> build\\lib.win-amd64-3.9\\fasttext\n",
      "copying python\\fasttext_module\\fasttext\\__init__.py -> build\\lib.win-amd64-3.9\\fasttext\n",
      "creating build\\lib.win-amd64-3.9\\fasttext\\util\n",
      "copying python\\fasttext_module\\fasttext\\util\\util.py -> build\\lib.win-amd64-3.9\\fasttext\\util\n",
      "copying python\\fasttext_module\\fasttext\\util\\__init__.py -> build\\lib.win-amd64-3.9\\fasttext\\util\n",
      "creating build\\lib.win-amd64-3.9\\fasttext\\tests\n",
      "copying python\\fasttext_module\\fasttext\\tests\\test_configurations.py -> build\\lib.win-amd64-3.9\\fasttext\\tests\n",
      "copying python\\fasttext_module\\fasttext\\tests\\test_script.py -> build\\lib.win-amd64-3.9\\fasttext\\tests\n",
      "copying python\\fasttext_module\\fasttext\\tests\\__init__.py -> build\\lib.win-amd64-3.9\\fasttext\\tests\n",
      "running build_ext\n",
      "building 'fasttext_pybind' extension\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tajak\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\setuptools\\dist.py:642: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  warnings.warn(\n",
      "warning: no files found matching 'PATENTS'\n",
      "error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n"
     ]
    }
   ],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting parse\n",
      "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
      "Building wheels for collected packages: parse\n",
      "  Building wheel for parse (setup.py): started\n",
      "  Building wheel for parse (setup.py): finished with status 'done'\n",
      "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24581 sha256=4a8d20c6e1e5f1885710520ff470cd14e6f95db73145e1cda465d5f24b299037\n",
      "  Stored in directory: c:\\users\\tajak\\appdata\\local\\pip\\cache\\wheels\\d6\\9c\\58\\ee3ba36897e890f3ad81e9b730791a153fce20caa4a8a474df\n",
      "Successfully built parse\n",
      "Installing collected packages: parse\n",
      "Successfully installed parse-1.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\tajak\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import fastText as ft\n",
    "import parse\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to data\n",
    "train = \"data/sled_categorization_TRAINSMALL_PREPROCESSED.txt\"\n",
    "\n",
    "test = \"data/sled_categorization_TEST_PREPROCESSED.txt\"\n",
    "\n",
    "dev = \"data/sled_categorization_DEV_PREPROCESSED.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the file to separate labels from text\n",
    "def parse_file(path: str):\n",
    "    \"\"\"Reads fasttext formatted file and returns labels, texts.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        content = f.readlines()\n",
    "    pattern = \"{label} {text}\\n\"\n",
    "    p = parse.compile(pattern)\n",
    "\n",
    "    labels, texts = list(), list()\n",
    "    for line in content:\n",
    "        rez = p.parse(line)\n",
    "        if rez is not None:\n",
    "            labels.append(rez[\"label\"])\n",
    "            texts.append(rez[\"text\"])\n",
    "        else:\n",
    "            print(\"error parsing line \", line)\n",
    "    return labels, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['na tolminskem se je dopoldne zgodila prometna nesreča v kateri je umrl 43-letni voznik osebnega avtomobila po tem ko je zapeljal v 100 metrov globoko grapo  nesreča se je zgodila ob 916 uri po prvih ugotovitvah policistov je domačin peljal iz tolmina proti vasi zadlaz - žabče kjer je v neposredni bližini ene od tamkajšnjih stanovanjskih hiš zapeljal levo z vozišča globoko približno 100 metrov v grapo  poleg policistov iz tolmina in nove gorice ter novogoriške gorske policijske enote so na kraju nesreče posredovali tudi gasilci pripadniki gorske reševalne službe in reševalci iz tolmina v nadaljevanju je bila ugotovljena in potrjena identiteta voznika in sicer je za posledicami telesnih poškodb v prometni nesreči podlegel 43-letni voznik so sporočili iz policijske uprave nova gorica zdravnica je odredila sanitarno obdukcijo ki jo bodo opravili na inštitutu za sodno medicino v ljubljani o nesreči so obvestili tudi preiskovalno sodnico in državno tožilstvo v novi gorici',\n",
       " 'na cesti zadlaz-žabče se je zgodila prometna nesreča v kateri je umrl 43-letni voznik osebnega avtomobila po prvih ugotovitvah je v neposredni bližini ene od tamkajšnjih stanovanjskih hiš zapeljal levo z vozišča približno 100 metrov globoko v grapo  ob 916 so novogoriške policiste obvestili o prometni nesreči s smrtnim izidom na cesti zadlaz-žabče v kateri je bil udeležen 43-letni voznik osebnega avtomobila z območja upravne enote tolmin  po prvih ugotovitvah je voznik peljal iz tolmina proti omenjeni vasi kjer je v neposredni bližini ene od tamkajšnjih stanovanjskih hiš zapeljal levo z vozišča približno 100 metrov globoko v grapo in pri tem utrpel tako hude poškodbe da je umrl  poleg policistov pp tolmin postaje prometne policije nova gorica in gorske policijske enote pu nova gorica so na kraju nesreče posredovali tudi gasilci pripadniki gorske reševalne službe in reševalci nmp zd tolmin zdravnica je odredila sanitarno obdukcijo ki jo bodo opravili na inštitutu za sodno medicino v ljubljani policija je o nesreči obvestila tudi pristojne pravosodne organe preiskovalno sodnico okrožnega sodišča in državno tožilstvo v novi gorici)',\n",
       " 'v sredo ob 1321 je bila novogoriška policija obveščena o sumu kaznivega dejanja hude telesne poškodbe na območju naselja dornberk kjer sta se v zasebnih prostorih fizično sprla dva moška stara 34 in 41 let takoj po obvestilu so bili na kraj napoteni policisti in kriminalisti ki so ugotovili da sta bila v sporu oba moška huje telesno poškodovana pri čemer je 34-letnik v sporu utrpel tudi vbodno rano z nožem drugi udeleženec spora pa je utrpel poškodbe obraza kasneje so oba moška reševalci odpeljali na nadaljnje zdravljenje v šempetrsko bolnišnico  policija je glede omenjenega primera obvestila tudi preiskovalnega sodnika okrožnega sodišča in državno tožilstvo v novi gorici zoper oba udeleženca bo po zaključku preiskave podana kazenska ovadba zaradi utemeljenega suma storitve kaznivega dejanja hude telesne poškodbe']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of texts and labels from the train file\n",
    "train_labels, train_texts = parse_file(train)\n",
    "\n",
    "# Inspect the results\n",
    "train_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__okolje',\n",
       " '__label__zdravje',\n",
       " '__label__gospodarstvo',\n",
       " '__label__kultura',\n",
       " '__label__crnakronika',\n",
       " '__label__vreme',\n",
       " '__label__zabava',\n",
       " '__label__izobrazevanje',\n",
       " '__label__prosticas',\n",
       " '__label__druzba',\n",
       " '__label__sport',\n",
       " '__label__znanost',\n",
       " '__label__politika']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of labels - by creating a set, we get only unique labels, then we transform the set back to a list\n",
    "LABELS = list(set(train_labels))\n",
    "\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_label(prediction):\n",
    "    \"\"\"Transforms predictions as returned by fasttext into pure labels.\"\"\"\n",
    "    return np.array(prediction[0])[:, 0]\n",
    "\n",
    "# Create a function to evaluate the results (it calculates the scores and creates a confusion matrix)\n",
    "def plot_cm():\n",
    "    \"\"\"\n",
    "    Plots confusion matrix for prediction on the test set.\n",
    "    Takes the predictions, named as y_pred, true values, named as y_true,\n",
    "    and labels, named as LABELS.\n",
    "    \n",
    "    Arguments:\n",
    "        save: whether the confusion matrix is saved. Defaults to False.\n",
    "        title: the title of the confusion matrix. Defaults to None.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.imshow(cm, cmap=\"Oranges\")\n",
    "    classNames = LABELS\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=90)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    microF1 = f1_score(y_true, y_pred, labels=LABELS, average =\"micro\")\n",
    "    macroF1 = f1_score(y_true, y_pred, labels=LABELS, average =\"macro\")\n",
    "\n",
    "    print(f\"{microF1:0.4}\")\n",
    "    print(f\"{macroF1:0.4}\")\n",
    "\n",
    "    metrics = f\"{microF1:0.4}, {macroF1:0.4}\"\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return microF1, macroF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search - epoch number\n",
    "\n",
    "I'll experiment with various epochs to see which epoch number provides the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started for epoch_num 10.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'fastText' has no attribute 'train_supervised'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6344/3719485364.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Training started for epoch_num {i}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     model = ft.train_supervised(input=train,\n\u001b[0m\u001b[0;32m      8\u001b[0m                                 \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                 \u001b[1;31m#lr = 0.7,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'fastText' has no attribute 'train_supervised'"
     ]
    }
   ],
   "source": [
    "# Define which epochs we want to try\n",
    "exp_range = [10, 50, 100, 150]\n",
    "\n",
    "for i in exp_range:\n",
    "    print(f\"Training started for epoch_num {i}.\")\n",
    "\n",
    "    model = ft.train_supervised(input=train,\n",
    "                                epoch = i,\n",
    "                                #lr = 0.7,\n",
    "                                #wordNgrams=1,\n",
    "                                verbose = 2\n",
    "                                            )\n",
    "\n",
    "    print(f\"Training finished. Testing started.\")\n",
    "\n",
    "    # Parse the dev files so that labels and texts are separated\n",
    "    y_true, y_texts = parse_file(dev)\n",
    "\n",
    "    # Evaluate the model on dev data\n",
    "    y_pred = model.predict(y_texts)\n",
    "    y_pred = prediction_to_label(y_pred)\n",
    "\n",
    "    # Plot the confusion matrix:\n",
    "    m, M = plot_cm()\n",
    "    \n",
    "    rezdict = dict(\n",
    "        microF1=m,\n",
    "        macroF1=M,\n",
    "        epoch_num = epoch,\n",
    "    )\n",
    "    results.append(rezdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.predict(\"V Celju se je zgodila nesreča, umrla je 42-letna ženska.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse the results of experiments\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "plt.style.use('_mpl-gallery')\n",
    "\n",
    "# make data\n",
    "\n",
    "x = []\n",
    "mi = []\n",
    "ma = []\n",
    "\n",
    "for i in results:\n",
    "    x.append(i['ngram'])\n",
    "    mi.append(i['microF1'])\n",
    "    ma.append(i[\"macroF1\"])\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(6,3), dpi=100)\n",
    "\n",
    "ax.plot(x, mi, linewidth=2.0, label=\"Micro F1\")\n",
    "ax.plot(x, ma, linewidth=2.0, label=\"Macro F1\")\n",
    "\n",
    "ax.set(xlim=(min(exp_range), max(exp_range)),\n",
    "       ylim=(0.5, 0.7),xticks=exp_range)\n",
    "\n",
    "ax.set_xlabel('Word n-Grams')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"N-grams.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results as JSON file\n",
    "import json\n",
    "\n",
    "with open(\"fastText_results.json\",\"w\") as file:\n",
    "  json.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Slovene embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading started\n",
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "# Unzip a file\n",
    "# importing necessary modules\n",
    "import wget, zipfile\n",
    "#from io import BytesIO\n",
    "print('Downloading started')\n",
    "\n",
    "#Defining the zip file URL\n",
    "url = \"https://www.clarin.si/repository/xmlui/bitstream/handle/11356/1204/embed.sl-token.ft.sg.vec.zip\"\n",
    "\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "embs = wget.download(url_name)\n",
    "print('Downloading Completed')\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile= zipfile.ZipFile(embs)\n",
    "zipfile.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_range = [1,2,3,4,5]\n",
    "\n",
    "for i in exp_range:\n",
    "    model = ft.train_supervised(input=train,\n",
    "                                epoch = 350,\n",
    "                                lr = 0.7,\n",
    "                                wordNgrams=1,\n",
    "                                verbose = 2,\n",
    "                                pretrainedVectors = \"data/embed.sl-token.ft.sg.vec\"\n",
    "                                            )\n",
    "    # Parse the dev files so that labels and texts are separated\n",
    "    y_true, y_texts = parse_file(dev)\n",
    "\n",
    "    # Evaluate the model on test data\n",
    "    y_pred = model.predict(y_texts)\n",
    "    y_pred = prediction_to_label(y_pred)\n",
    "\n",
    "    # Plot the confusion matrix:\n",
    "    m, M = plot_cm(save=False, title=f\"NGram: {i}\")\n",
    "    \n",
    "    rezdict = dict(\n",
    "        microF1=m,\n",
    "        macroF1=M,\n",
    "        ngram=i\n",
    "    )\n",
    "    results.append(rezdict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0555c586899327de5ef52b99d3d9e7099ad5c798fa5f7641c78f37c465123c9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

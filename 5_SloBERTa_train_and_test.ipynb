{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJMsD_me-QY5"
      },
      "source": [
        "# Training (fine-tuning) SloBERTa Transformer model on SLED smalltrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf0Oql_1HOtk"
      },
      "source": [
        "This notebook is prepared to be viewed on Google Colab. However, I performed most of the experiment on Kaggle (by importing the same notebook and data) instead of Google Colab, because while Kaggle gives you 35-40 hours of GPU per week, Google Colab does not state how much working on GPU it allows, and after I spent one day doing hyperparameter search, I got a message that I spent it all without stating when I'll be able to use it again. Therefore, I recommend using Kaggle for lengthy experiments on GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK4aNUl8-QY_"
      },
      "source": [
        "Before starting, click on the \"RAM\" and \"Disk\" information on the top right part of the page and click \"Change runtime type\" > Choose \"GPU\" as \"Hardware accelerator\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:04:09.436216Z",
          "iopub.status.busy": "2022-09-05T06:04:09.435827Z",
          "iopub.status.idle": "2022-09-05T06:04:09.967336Z",
          "shell.execute_reply": "2022-09-05T06:04:09.966372Z",
          "shell.execute_reply.started": "2022-09-05T06:04:09.436182Z"
        },
        "id": "lTXoWplYG48h",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# install the libraries necessary for data wrangling, prediction and result analysis\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score, recall_score\n",
        "import torch\n",
        "from numba import cuda\n",
        "import time\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:02:51.479216Z",
          "iopub.status.busy": "2022-09-05T06:02:51.478415Z",
          "iopub.status.idle": "2022-09-05T06:03:33.067084Z",
          "shell.execute_reply": "2022-09-05T06:03:33.066071Z",
          "shell.execute_reply.started": "2022-09-05T06:02:51.479100Z"
        },
        "id": "zZqgErWfG48i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Install transformers\n",
        "# (this needs to be done on Colab each time you start the session).\n",
        "# For information on how to install transformers and simpletransformers on you machine,\n",
        "# follow simpletransformers instructions: https://simpletransformers.ai/docs/installation/\n",
        "!pip install -q transformers\n",
        "\n",
        "# Install the simpletransformers\n",
        "!pip install -q simpletransformers\n",
        "from simpletransformers.classification import ClassificationModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:03:33.070137Z",
          "iopub.status.busy": "2022-09-05T06:03:33.069286Z",
          "iopub.status.idle": "2022-09-05T06:03:58.743518Z",
          "shell.execute_reply": "2022-09-05T06:03:58.742411Z",
          "shell.execute_reply.started": "2022-09-05T06:03:33.070081Z"
        },
        "id": "FvvJgvBKG48i",
        "outputId": "617f9aae-2093-4ea5-c8a4-4f3db382b65b",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Install wandb - this will be useful for inspecting the results of a hyperparameter search.\n",
        "# You need to create an account on Wandb: https://wandb.ai/\n",
        "!pip install -q wandb\n",
        "\n",
        "import wandb\n",
        "\n",
        "# Login to wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WjS5ZNZG48k"
      },
      "source": [
        "### Import the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LPZfZ9J-QZE"
      },
      "source": [
        "You need to prepare the data into a format that is accepted by Transformers (dataframe with the first column \"text\" and the second column \"labels\"). The data was prepared according to the code here: https://github.com/TajaKuzman/FastText-Classification-SLED/blob/main/0-analyse-data-prepare-for-transformers.ipynb. Before importing, upload the data to Google Colab (by clicking on the Folder icon on the left of the site and clicking the \"Upload to session storage\" icon)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:04:15.193978Z",
          "iopub.status.busy": "2022-09-05T06:04:15.193038Z",
          "iopub.status.idle": "2022-09-05T06:04:15.693308Z",
          "shell.execute_reply": "2022-09-05T06:04:15.692290Z",
          "shell.execute_reply.started": "2022-09-05T06:04:15.193942Z"
        },
        "id": "bnkXFivrG48k",
        "outputId": "75cdcc1f-7ada-4eae-c67b-5a3b78504333",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (9990, 2), Dev shape: (1296, 2), Test shape: (1299, 2).\n"
          ]
        }
      ],
      "source": [
        "Colab_path = \"/content\"\n",
        "\n",
        "train_df = pd.read_csv(f\"{Colab_path}/SLED-for-Transformers-train.csv\", sep=\"\\t\", index_col=0)\n",
        "dev_df = pd.read_csv(f\"{Colab_path}/SLED-for-Transformers-dev.csv\", sep=\"\\t\", index_col = 0)\n",
        "test_df = pd.read_csv(f\"{Colab_path}/SLED-for-Transformers-test.csv\", sep=\"\\t\", index_col = 0)\n",
        "\n",
        "# See the sizes of splits.\n",
        "# I noticed that when I ran this code on Google Colab,\n",
        "# it did not import the entire train split every time (sometimes the size was a couple instances smaller than it should be)\n",
        "# - if this happens, just run this cell again, until the size is fine (it should be 9990). I did not have this problem on Kaggle.\n",
        "print(\"Train shape: {}, Dev shape: {}, Test shape: {}.\".format(train_df.shape, dev_df.shape, test_df.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:04:21.627961Z",
          "iopub.status.busy": "2022-09-05T06:04:21.627371Z",
          "iopub.status.idle": "2022-09-05T06:04:21.642537Z",
          "shell.execute_reply": "2022-09-05T06:04:21.641544Z",
          "shell.execute_reply.started": "2022-09-05T06:04:21.627929Z"
        },
        "id": "vmt2VPzoG48k",
        "outputId": "15f3aca5-0ad4-48be-b3dc-05a53a593715",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text       labels\n",
              "0  na tolminskem se je dopoldne zgodila prometna ...  crnakronika\n",
              "1  na cesti zadlaz-žabče se je zgodila prometna n...  crnakronika\n",
              "2  v sredo ob 1321 je bila novogoriška policija o...  crnakronika\n",
              "3  malo po 16 uri je v svetem duhu na ostrem vrhu...  crnakronika\n",
              "4  v eksploziji pirotehnike je bil v soboto popol...  crnakronika"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b12aee83-f9af-43ac-ae39-0b9e0502c3e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>na tolminskem se je dopoldne zgodila prometna ...</td>\n",
              "      <td>crnakronika</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>na cesti zadlaz-žabče se je zgodila prometna n...</td>\n",
              "      <td>crnakronika</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v sredo ob 1321 je bila novogoriška policija o...</td>\n",
              "      <td>crnakronika</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>malo po 16 uri je v svetem duhu na ostrem vrhu...</td>\n",
              "      <td>crnakronika</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v eksploziji pirotehnike je bil v soboto popol...</td>\n",
              "      <td>crnakronika</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b12aee83-f9af-43ac-ae39-0b9e0502c3e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b12aee83-f9af-43ac-ae39-0b9e0502c3e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b12aee83-f9af-43ac-ae39-0b9e0502c3e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Inspect the beginning of the train split.\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJzQ5uQcG48k"
      },
      "source": [
        "## Training and saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh9j3bUIG48l"
      },
      "source": [
        "We will use the monolingual SloBERTa model\n",
        "https://huggingface.co/EMBEDDIA/sloberta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7FvuvGt-QZG"
      },
      "source": [
        "For training, I'll use the simple transformer library which is much more user-friendly than the hugging face library. They also have very nice instructions on everything: https://simpletransformers.ai/docs/installation/, including tutorials, I recommend reading it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:04:25.185697Z",
          "iopub.status.busy": "2022-09-05T06:04:25.185232Z",
          "iopub.status.idle": "2022-09-05T06:04:25.194299Z",
          "shell.execute_reply": "2022-09-05T06:04:25.193386Z",
          "shell.execute_reply.started": "2022-09-05T06:04:25.185662Z"
        },
        "id": "IpPQuSt4G48l",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set the \"TOKENIZERS_PARALLELISM\" to false to avoid getting an error when training the model.\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:04:27.123887Z",
          "iopub.status.busy": "2022-09-05T06:04:27.123526Z",
          "iopub.status.idle": "2022-09-05T06:04:27.136553Z",
          "shell.execute_reply": "2022-09-05T06:04:27.135203Z",
          "shell.execute_reply.started": "2022-09-05T06:04:27.123859Z"
        },
        "id": "CsA2-xYyG48l",
        "outputId": "2f59ba32-6af5-4379-d69d-659650efda17",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['crnakronika',\n",
              " 'druzba',\n",
              " 'gospodarstvo',\n",
              " 'izobrazevanje',\n",
              " 'kultura',\n",
              " 'okolje',\n",
              " 'politika',\n",
              " 'prosticas',\n",
              " 'sport',\n",
              " 'vreme',\n",
              " 'zabava',\n",
              " 'zdravje',\n",
              " 'znanost']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Create a list of labels\n",
        "LABELS = train_df.labels.unique().tolist()\n",
        "LABELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:04:30.917914Z",
          "iopub.status.busy": "2022-09-05T06:04:30.917115Z",
          "iopub.status.idle": "2022-09-05T06:04:37.446097Z",
          "shell.execute_reply": "2022-09-05T06:04:37.445187Z",
          "shell.execute_reply.started": "2022-09-05T06:04:30.917881Z"
        },
        "id": "2Uk3QBetG48l",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize Wandb (change the names of project, entity and \"name\" according to your project in Wandb)\n",
        "wandb.init(project=\"SLED-categorization\", entity=\"tajak\", name=\"SloBERTa-hyperparameter-search\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:04:40.897312Z",
          "iopub.status.busy": "2022-09-05T06:04:40.896771Z",
          "iopub.status.idle": "2022-09-05T06:04:40.910083Z",
          "shell.execute_reply": "2022-09-05T06:04:40.909004Z",
          "shell.execute_reply.started": "2022-09-05T06:04:40.897264Z"
        },
        "id": "w5dNhA4hG48m",
        "outputId": "a350ab5c-ffb2-410d-e840-95b24aebbac2",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1248"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Calculate how many steps will each epoch have\n",
        "# Num steps in epoch = training samples / batch size\n",
        "steps_per_epoch = int(9990/8)\n",
        "steps_per_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2gsrgCQIImz"
      },
      "source": [
        "### Hyperparameter search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-29T06:59:27.044920Z",
          "iopub.status.busy": "2022-07-29T06:59:27.044530Z",
          "iopub.status.idle": "2022-07-29T06:59:27.051272Z",
          "shell.execute_reply": "2022-07-29T06:59:27.050401Z",
          "shell.execute_reply.started": "2022-07-29T06:59:27.044871Z"
        },
        "id": "oBUMVyTBG48m",
        "trusted": true
      },
      "source": [
        "I evaluated the model per every 10th epoch - per 12480 steps. I first trained the model while evaluating it to find the optimal number of epochs. Based on the information on changes in training and evaluation loss which I observed on Wandb, I found out which epochs are the most optimal (epochs before which the evaluation loss starts rising again). Then I trained the model and tested it on dev for each of possible optimal epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T11:14:46.044012Z",
          "iopub.status.busy": "2022-08-23T11:14:46.043127Z",
          "iopub.status.idle": "2022-08-23T11:15:42.456646Z",
          "shell.execute_reply": "2022-08-23T11:15:42.455651Z",
          "shell.execute_reply.started": "2022-08-23T11:14:46.043973Z"
        },
        "id": "bCz4gGWzG48m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a TransformerModel\n",
        "sloberta_model = ClassificationModel(\n",
        "    # For each model, you need to specify its model type and its name.\n",
        "    # You can find this information on the hugging face page of the model (https://huggingface.co/EMBEDDIA/sloberta):\n",
        "    # you'll find the model type in files > config.json; and the name if you click on the button \"Use in Transformers\"\n",
        "        \"camembert\", \"EMBEDDIA/sloberta\",\n",
        "        num_labels=len(LABELS),\n",
        "        use_cuda=True,\n",
        "        # Define the hyperparameters (I'll only experiment with epochs, for others,\n",
        "        # I just use the values that worked nicely in past experiments)\n",
        "        args= {\n",
        "            \"num_train_epochs\": 30,\n",
        "            \"train_batch_size\":8,\n",
        "            \"learning_rate\": 1e-5,\n",
        "            \"labels_list\": LABELS,\n",
        "            \"max_seq_length\": 512,\n",
        "            # Here, write in the name of your Wandb project\n",
        "            \"wandb_project\": 'SLED-categorization',\n",
        "            \"silent\": True,                        \n",
        "            # Use these parameters if you want to evaluate during training\n",
        "            \"evaluate_during_training\": True,\n",
        "            \"evaluate_during_training_steps\": steps_per_epoch*10,\n",
        "            \"evaluate_during_training_verbose\": True,\n",
        "            \"use_cached_eval_features\": True,\n",
        "            'reprocess_input_data': True,\n",
        "            # I use the hyperparameters bellow to prevent filling up the memory.\n",
        "            # Disable no_save: True and no_cache: True if you want to save the model.\n",
        "            \"overwrite_output_dir\": True,\n",
        "            \"no_cache\": True,\n",
        "            \"no_save\": True,\n",
        "            \"save_steps\": -1,\n",
        "            \"save_model_every_epoch\":False\n",
        "            }\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T11:16:20.475361Z",
          "iopub.status.busy": "2022-08-23T11:16:20.474372Z",
          "iopub.status.idle": "2022-08-23T11:35:47.348058Z",
          "shell.execute_reply": "2022-08-23T11:35:47.346990Z",
          "shell.execute_reply.started": "2022-08-23T11:16:20.475323Z"
        },
        "id": "isOQFWADG48m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "# Log time to see how long it takes\n",
        "training_start_time = time.time()\n",
        "\n",
        "# Train the model and evaluate it - you need to specify the evaluation split as well\n",
        "sloberta_model.train_model(train_df, eval_df = dev_df)\n",
        "\n",
        "print(f\"Training and evaluation took {round((time.time() - training_start_time)/60,2)} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XApAjnsUG48m"
      },
      "source": [
        "Based on evaluation during training, analysed on Wandb, the optimum epoch is between 2 and 8 epochs (see graph on GitHub: https://github.com/TajaKuzman/FastText-Classification-SLED#hyperparameter-search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:07:33.838298Z",
          "iopub.status.busy": "2022-09-05T06:07:33.837912Z",
          "iopub.status.idle": "2022-09-05T06:07:33.844953Z",
          "shell.execute_reply": "2022-09-05T06:07:33.843829Z",
          "shell.execute_reply.started": "2022-09-05T06:07:33.838264Z"
        },
        "id": "753cKK1REqw3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a list into which you'll save the results.\n",
        "previous_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T08:21:09.613260Z",
          "iopub.status.busy": "2022-09-05T08:21:09.612883Z",
          "iopub.status.idle": "2022-09-05T08:21:09.626990Z",
          "shell.execute_reply": "2022-09-05T08:21:09.625801Z",
          "shell.execute_reply.started": "2022-09-05T08:21:09.613229Z"
        },
        "id": "wu3i2hUYG48m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a function that you'll use for testing the model\n",
        "\n",
        "def testing(test_df, test_name, epoch):\n",
        "    \"\"\"\n",
        "    This function takes the test dataset and applies the trained model on it to infer predictions.\n",
        "    It also prints and saves a confusion matrix, calculates the F1 scores and saves the results in a list of results.\n",
        "\n",
        "    Args:\n",
        "    - test_df (pandas DataFrame)\n",
        "    - test_name\n",
        "    - epoch: num_train_epochs\n",
        "    \"\"\"\n",
        "    # Get the true labels\n",
        "    y_true = test_df.labels\n",
        "\n",
        "    # Define the model\n",
        "    model = sloberta_model\n",
        "    \n",
        "    # Calculate the model's predictions on test\n",
        "    def make_prediction(input_string):\n",
        "        return model.predict([input_string])[0][0]\n",
        "\n",
        "    # Use the model to predict the labels\n",
        "    y_pred = test_df.text.apply(make_prediction)\n",
        "\n",
        "    # Calculate the scores\n",
        "    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n",
        "    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n",
        "    print(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}\")\n",
        "\n",
        "    # Plot the confusion matrix:\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
        "    plt.figure(figsize=(9, 9))\n",
        "    plt.imshow(cm, cmap=\"Oranges\")\n",
        "    for (i, j), z in np.ndenumerate(cm):\n",
        "        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n",
        "    classNames = LABELS\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    tick_marks = np.arange(len(classNames))\n",
        "    plt.xticks(tick_marks, classNames, rotation=90)\n",
        "    plt.yticks(tick_marks, classNames)\n",
        "    plt.title(f\"{test_name}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig1 = plt.gcf()\n",
        "    plt.show()\n",
        "    plt.draw()\n",
        "    # Save the confusion matrix\n",
        "    fig1.savefig(f\"Confusion-matrix-{test_name}.png\",dpi=100)\n",
        "\n",
        "    # Print classification report\n",
        "    print(classification_report(y_true, y_pred, labels = LABELS))\n",
        "\n",
        "    # Save the results:\n",
        "    rezdict = {\n",
        "        \"experiment\": test_name,\n",
        "        \"num_train_epochs\": epoch,\n",
        "        \"train_batch_size\":8,\n",
        "        \"learning_rate\": 1e-5,\n",
        "        \"microF1\": micro,\n",
        "        \"macroF1\": macro,\n",
        "        \"y_true\": y_true.to_dict(),\n",
        "        \"y_pred\": y_pred.to_dict(),\n",
        "        }\n",
        "    previous_results.append(rezdict)\n",
        "\n",
        "    #Save intermediate results (just in case)\n",
        "    backup = []\n",
        "    backup.append(rezdict)\n",
        "    with open(f\"backup-results-{test_name}.json\", \"w\") as backup_file:\n",
        "        json.dump(backup,backup_file, indent= \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-02T09:52:33.924310Z",
          "iopub.status.busy": "2022-09-02T09:52:33.923585Z",
          "iopub.status.idle": "2022-09-02T13:04:42.035418Z",
          "shell.execute_reply": "2022-09-02T13:04:42.034227Z",
          "shell.execute_reply.started": "2022-09-02T09:52:33.924270Z"
        },
        "id": "Xqhyr3fRG48n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Train the model for various epochs to find the optimum number of epochs\n",
        "#epochs = [2, 4, 6, 8]\n",
        "epochs = [8, 10]\n",
        "\n",
        "for epoch in epochs:\n",
        "    sloberta_model = ClassificationModel(\n",
        "                \"camembert\", \"EMBEDDIA/sloberta\",\n",
        "                num_labels=len(LABELS),\n",
        "                use_cuda=True,\n",
        "                args= {\n",
        "                    \"overwrite_output_dir\": True,\n",
        "                    \"num_train_epochs\": epoch,\n",
        "                    \"train_batch_size\":8,\n",
        "                    \"learning_rate\": 1e-5,\n",
        "                    \"labels_list\": LABELS,\n",
        "                    # The following parameters (no_cache, no_save) are commented out if I want to save the model\n",
        "                    \"no_cache\": True,\n",
        "                    \"no_save\": True,\n",
        "                    \"max_seq_length\": 512,\n",
        "                    \"save_steps\": -1,\n",
        "                    # Only the trained model will be saved - to prevent filling all of the space\n",
        "                    \"save_model_every_epoch\":False,\n",
        "                    \"wandb_project\": 'SLED-categorization',\n",
        "                    \"silent\": True,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "    # Train the model\n",
        "    sloberta_model.train_model(train_df)\n",
        "    \n",
        "    # Test the model on dev_df\n",
        "    testing(dev_df, f\"SLED-trainsmall-SLOBERTA-dev-epoch-search:{epoch}\", epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igKmu89GG48n"
      },
      "source": [
        "Optimum number of epochs is 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-02T13:26:56.341204Z",
          "iopub.status.busy": "2022-09-02T13:26:56.340563Z",
          "iopub.status.idle": "2022-09-02T13:26:56.387409Z",
          "shell.execute_reply": "2022-09-02T13:26:56.386422Z",
          "shell.execute_reply.started": "2022-09-02T13:26:56.341151Z"
        },
        "id": "W4eE9BU1G48n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Compare the results by creating a dataframe from the previous_results dictionary:\n",
        "results_df = pd.DataFrame(previous_results)\n",
        "\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-02T13:27:27.025246Z",
          "iopub.status.busy": "2022-09-02T13:27:27.024878Z",
          "iopub.status.idle": "2022-09-02T13:27:27.047994Z",
          "shell.execute_reply": "2022-09-02T13:27:27.047122Z",
          "shell.execute_reply.started": "2022-09-02T13:27:27.025214Z"
        },
        "id": "RrGQ_xkcG48n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Save the file with updated results.\n",
        "with open(\"SLED-SloBERTa-trainsmall-hyperparameter-search-results.json\", \"w\") as results_file:\n",
        "    json.dump(previous_results,results_file, indent= \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg5YB3Gb-QZL"
      },
      "source": [
        "Train and save the model, using 8 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:08:05.401331Z",
          "iopub.status.busy": "2022-09-05T06:08:05.400946Z",
          "iopub.status.idle": "2022-09-05T06:08:41.737044Z",
          "shell.execute_reply": "2022-09-05T06:08:41.736097Z",
          "shell.execute_reply.started": "2022-09-05T06:08:05.401298Z"
        },
        "id": "kL5xMuUJG48o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a TransformerModel\n",
        "sloberta_model = ClassificationModel(\n",
        "        \"camembert\", \"EMBEDDIA/sloberta\",\n",
        "        num_labels=len(LABELS),\n",
        "        use_cuda=True,\n",
        "        args= {\n",
        "            \"overwrite_output_dir\": True,\n",
        "            \"num_train_epochs\": 8,\n",
        "            \"train_batch_size\":8,\n",
        "            \"learning_rate\": 1e-5,\n",
        "            \"labels_list\": LABELS,\n",
        "            # no_cache and no_save are commented out because I want to save the model\n",
        "            #\"no_cache\": True,\n",
        "            #\"no_save\": True,\n",
        "            \"max_seq_length\": 512,\n",
        "            \"save_steps\": -1,\n",
        "            # Only the trained model will be saved - to prevent filling all of the space\n",
        "            \"save_model_every_epoch\":False,\n",
        "            \"wandb_project\": 'SLED-categorization',\n",
        "            \"silent\": True,\n",
        "            }\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T06:08:45.777824Z",
          "iopub.status.busy": "2022-09-05T06:08:45.777470Z",
          "iopub.status.idle": "2022-09-05T07:25:39.092518Z",
          "shell.execute_reply": "2022-09-05T07:25:39.091290Z",
          "shell.execute_reply.started": "2022-09-05T06:08:45.777795Z"
        },
        "id": "ct5DPfhZG48o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Train and save the model\n",
        "sloberta_model.train_model(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T07:57:14.338961Z",
          "iopub.status.busy": "2022-09-05T07:57:14.338289Z",
          "iopub.status.idle": "2022-09-05T07:57:29.603224Z",
          "shell.execute_reply": "2022-09-05T07:57:29.601912Z",
          "shell.execute_reply.started": "2022-09-05T07:57:14.338920Z"
        },
        "id": "LGmsh6oFG48o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Save the trained model to Wandb (so you'll be able to access it later - see https://github.com/TajaKuzman/FastText-Classification-SLED/blob/main/Saved_models.md for information on how to use saved models)\n",
        "run = wandb.init(project=\"SLED-categorization\", entity=\"tajak\", name=\"saving-trained-model\")\n",
        "trained_model_artifact = wandb.Artifact(\"SLED-SloBERTa-trainsmall-classifier\", type=\"model\", description=\"a SloBERTa model fine-tuned on the Slovene SLED (trainsmall) dataset, annotated with topic.\")\n",
        "trained_model_artifact.add_dir(\"/kaggle/working/outputs\")\n",
        "run.log_artifact(trained_model_artifact)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciYU1YWe-QZM"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T08:05:42.746462Z",
          "iopub.status.busy": "2022-09-05T08:05:42.745469Z",
          "iopub.status.idle": "2022-09-05T08:05:42.753656Z",
          "shell.execute_reply": "2022-09-05T08:05:42.752310Z",
          "shell.execute_reply.started": "2022-09-05T08:05:42.746415Z"
        },
        "trusted": true,
        "id": "GAICFRNp-QZM"
      },
      "outputs": [],
      "source": [
        "# Create a list to save results into\n",
        "previous_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T08:22:01.725428Z",
          "iopub.status.busy": "2022-09-05T08:22:01.724921Z",
          "iopub.status.idle": "2022-09-05T08:31:18.577805Z",
          "shell.execute_reply": "2022-09-05T08:31:18.576660Z",
          "shell.execute_reply.started": "2022-09-05T08:22:01.725367Z"
        },
        "trusted": true,
        "id": "-Lyu4iDJ-QZM"
      },
      "outputs": [],
      "source": [
        "# Test the model on the test split\n",
        "testing(test_df, \"SloBERTa-test\", 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T08:32:58.213428Z",
          "iopub.status.busy": "2022-09-05T08:32:58.212353Z",
          "iopub.status.idle": "2022-09-05T08:32:58.246688Z",
          "shell.execute_reply": "2022-09-05T08:32:58.245693Z",
          "shell.execute_reply.started": "2022-09-05T08:32:58.213378Z"
        },
        "trusted": true,
        "id": "b98g03_G-QZM"
      },
      "outputs": [],
      "source": [
        "# Compare the results by creating a dataframe from the previous_results dictionary:\n",
        "results_df = pd.DataFrame(previous_results)\n",
        "\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-05T08:33:07.700289Z",
          "iopub.status.busy": "2022-09-05T08:33:07.699599Z",
          "iopub.status.idle": "2022-09-05T08:33:07.723689Z",
          "shell.execute_reply": "2022-09-05T08:33:07.722655Z",
          "shell.execute_reply.started": "2022-09-05T08:33:07.700255Z"
        },
        "trusted": true,
        "id": "6h-vjZZD-QZN"
      },
      "outputs": [],
      "source": [
        "# Save the results\n",
        "with open(\"SloBERTa-SLED-trainsmall-experiments-Results.json\", \"w\") as results_file:\n",
        "    json.dump(previous_results,results_file, indent= \"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "93d4a695e88da557f0853396ea51c6018a728735920333b5bdbaaf747b0b49f9"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}